<!doctype html>
<head>
<!-- Basic Page Needs -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- <link rel="icon" type="image/png" href="images/favicon.png"> -->

<title>Alice Lab for Computational Worldmaking</title>
<meta name="description" content="Alice Lab for Computational Worldmaking">
<meta name="author" content="Graham Wakefield">

<!-- FONT -->
<link href="http://fonts.googleapis.com/css?family=Roboto:100,400,700&subset=cyrillic-ext,greek-ext,latin-ext" rel="stylesheet">

<!-- <link rel="stylesheet" href="css/robotolight.css" type="text/css" /> -->

<!-- CSS -->
<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" href="css/skeleton.css">

<style>

#top {
	position: fixed;
	top: 0;
	left: 0;
	width: 100%;
	height: 3em;
	
	background-color: #444;
	color: #fff;
	
	display: flex;
	align-items: center;
}

header {
	width:90%; max-width: 960px;	/* page width */
	margin: 0 auto 0 auto;
	
	color: #fff;
	font-family: 'robotothin', 'Helvetica Neue Light', Helvetica, Arial, sans-serif;
	font-size: 1em;
}

header b {
	color: #fff;
	font-size: 1.618em;
}

main {
	width:90%; max-width: 960px;	/* page width */
	margin: 4em auto 4em auto;
	/*margin-top: 2em;
	margin-bottom: 30px;*/
	/*background-color: #ccc;*/
}

#bottom {
	position: fixed;
	bottom: 0;
	left: 0;
	width: 100%;
	height: 4em;
	font-size: 0.8em;
	
	display: flex;
	align-items: center;
	
	background-color: #444;
	color: #bbb;
	
}

footer {
	width:90%; max-width: 960px;	/* page width */
	margin: 0 auto 0 auto;
	
}

footer a { 
	color: inherit; 
} 

img {
	max-width: 100%;
}

.pull-left {
	float: left;
	width: 25%;
	margin-right: 1em;
}
.pull-right {
	float: right;
	width: 40%;
	margin-left: 1em;
}

</style>

</head>
<body>

<div id="top">
<header>
<b>Alice Lab</b> for computational worldmaking
</header>
</div>


<main>

<section>
<p><img src="images/IMG_4260.jpg" alt="Archipelago"></p>
<p>The <strong>Alice lab for Computational Worldmaking</strong> develops transferable knowledge and creative coding technology as well as intensifying computationally literate art practice in the construction of responsive artificial worlds experienced through rapidly emerging mixed/hybrid reality technologies including both Virtual Reality (VR) and Augmented Reality (AR). Inspired by the creativity of nature, its research-creation program leverages strong simulation and the self-modifying capacity of computational media to create artificial worlds whose rules can be rewritten while participants interact within them, pioneering heightened levels of human-machine interaction and intensified aesthetic experience through meaningful engagement using the whole body. Cutting across work in generative art, computer graphics, human-computer interaction, artificial life, complex systems and compiler technology, this research program reinforces influential work at York in augmented reality, computer vision, stereoscopic cinema and ubiquitous screens, and results in transferable research, open-source tools, and novel creative works. </p>
<p>It is directed by <a href="http://www.grahamwakefield.net">Graham Wakefield</a>, Assistant Professor appointed to the <a href="http://digital-media.ampd.yorku.ca/profile/graham-wakefield/">Department of Computational Arts</a> and the <a href="http://vaah.ampd.yorku.ca">Department of Visual Art and Art History</a> in the <a href="http://ampd.yorku.ca">School of the Arts, Media, Performance, and Design (AMPD)</a>, and a <a href="http://www.chairs-chaires.gc.ca/home-accueil-eng.aspx">Canada Research Chair</a> (Tier II) in interactive information visualization at York University, Toronto, Canada. Wakefield&#39;s art installations have been exhibited at leading international museums and peer-reviewed events in areas of digital media, computation and culture, including ZKM Karlsruhe, La Gaite Lyrique Paris, and SIGGRAPH, and have attained national and international awards including VIDA, the premier art &amp; artificial life competition (2014). He was previously an integral researcher at the <a href="http://www.allosphere.ucsb.edu">AlloSphere</a>, a unique 3-storey spherical multi-user virtual reality instrument, UC Santa Barbara 2007-2012, creating multi-screen artworks and scientific visualizations, and software infrastructure for worldmaking that not only forms the foundation for most projects in the AlloSphere today, but is also widely used beyond including by internationally-renowned artists. He is also co-author of a framework for creative coding (<a href="https://cycling74.com/products/max">Gen for Max/MSP, 2011</a>) which now has tens of thousands of users, and is used by industrial design labs and incorporated into courses at several major universities. At York he is also a member of <a href="http://www.cvr.yorku.ca">The Centre for Vision Research</a> and <a href="http://sensorium.info.yorku.ca">Sensorium</a> organized research units. The computational worldmaking lab continues the research-creation activity from Dr. Wakefield&#39;s former position at the <a href="http://ct.kaist.ac.kr">Graduate School of Culture Technology</a>, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea.</p>
<h2 id="support">Support</h2>
<ul>
<li><a href="http://www.chairs-chaires.gc.ca">Canada Research Chairs program</a>: Canada Research Chair Tier II (Interactive Visualization)</li>
<li><a href="http://www.innovation.ca">The Canada Foundation for Innovation (CFI)</a> <a href="http://www.innovation.ca/en/OurFunds/CFIFunds/JohnREvansLeadersFund/JELF">John R. Evans Leaders Fund (JELF)</a></li>
<li><a href="https://www.ontario.ca/page/ontario-research-fund">The Ontario Research Fund</a>, Small Infrastructure Fund</li>
<li><a href="http://livingarchitecturesystems.com">Living Architecture Systems Group SSHRC Partnership</a></li>
<li>Ontario government Early Researcher Awards program</li>
<li>SSHRC Connections</li>
<li><a href="http://vista.info.yorku.ca">VISTA Vision Science to Applications CFREF</a></li>
<li><a href="http://ampd.yorku.ca">The School of the Arts, Media, Performance and Design (AMPD) at York University</a></li>
<li><a href="http://www.yufa.ca/">York University Faculty Association</a></li>
<li><a href="http://blog.naver.com/artiencelab">Daejeon Culture and Arts Foundation (Artience Program)</a></li>
<li><a href="http://english.sfac.or.kr/">Seoul Foundation for Arts and Culture (Imagination Powerhouse Program)</a></li>
</ul>
<h3 id="research-streams">Research Streams</h3>
<h4 id="artificial-nature">Artificial Nature</h4>
<p><img src="images/ArtificialNatures.jpg" alt="Artificial Natures"></p>
<p>This research stream synthesizes new “artificial natures”: installations integrating software models drawn from systems biology, artificial intelligence, and other biologically inspired sciences, with immersive virtual- and mixed-reality environments in physical space, such that humans take upon new roles within adaptive ecosystems. The installations are displayed at high-levels of sensory immersion, through the use of large-scale displays, wide fields of view, stereoscopic rendering, high frame-rates, and spatialized audio. Each artificial nature presents a computational world with its own physics and biology, within which visitors interact to become essential participants within the system. An ultimate goal is to bring the generative capacity of computation into an experiential level reminiscent of, yet different to, the open-endedness of the natural world; to evoke extended aesthetic experiences that recapitulate something akin to the child-like wonder regarding the complexity, beauty, and sublimity of nature. This project extends a line of research initiated in 2008 by Haru Ji and Graham Wakefield, resulting in over thirty-five exhibits across nine countries, including festivals such as SIGGRAPH (Yokohama), Microwave (Hong Kong), Digital Art Festival (Taipei), conferences such as ISEA (Singapore), and EvoWorkshops (Tubingen), and venues including ZKM (Germany), La Gaite Lyrique (Paris), CAFA (Beijing) and City Hall (Seoul), and recognition in the international artificial life art award VIDA. <a href="http://www.artificialnature.net">Project website</a>.</p>
<h4 id="worldmaking-framework">Worldmaking Framework</h4>

<span class='pull-left'>
<p><img src="images/Worldmaking.jpg" alt="Worldmaking"></p>

</span>
<p>Developing software addressing the challenges of integrating complex models and algorithms of process and behaviour, 3D motion tracking, mixed-reality immersive display, and live and collaborative creativity. The resulting framework will be an environment for collaborative development and “creative coding”, in which designers and artists to work at high structural levels, specifying goals in visual and schematic terms, using design patterns of model-driven engineering and code generation to implement the underlying code automatically, and just-in-time compilation to tighten this loop between schematic expression of idea to its optimally efficient implementation down to scales of milliseconds, such that in the moment insights can be experienced and evaluated at minimal cognitive cost, and without sacrificing complexity or bandwidth of the resulting systems. Outcomes will be relevant to the domains of as digital media arts, architecture, digital sculpture, entertainment, gaming, computer science, and art/science collaboration. </p>
<h4 id="collaborative-creativity-for-virtual-reality">Collaborative Creativity for Virtual Reality</h4>

<span class='pull-left'>
<p><img src="images/CreativityVR.jpg" alt="Collaborative Creativity for Virtual Reality"></p>

</span>
<p>2016 heralds affordable consumer virtual reality (VR), however industry leaders assert that research in content and software design remains urgent, and media figures highlight creative applications as focal points for this research. This research stream focuses on the creation of worlds from <em>within VR</em>, addressing three complementary axes: 1) a symbolic-algorithmic axis of rewriting the code of a world while immersed within it, as a new direction of live coding, 2) an embodied axis, augmenting hand and body gestures-in-motion with dynamics-driven simulation to create far richer and more complex forms that nevertheless retain the gestural nuances of the creator, and 3) collaborative methods to co-author worlds as a social process, in real-time. It will result in rigorously researched interaction models, transferable technologies, and unique training in emerging digital media. </p>
<h4 id="curious-spaces">Curious Spaces</h4>

<span class='pull-left'>
<p><img src="images/EnvironmentsThatHear.jpg" alt="Environments That Hear"></p>

</span>
<p>A pursuit of into new depths of mixed-reality human-machine interaction and responsive environments toward a larger goal of intensifying aesthetic experience through meaningful collaborative human-machine interaction over extended durations. This project will explore strategies by which software can propose changes to make to itself, and accept or reject these changes according to reward functions that privilege neither easily predictable nor entirely unpredictable patterns, but which serve intrinsic high-level goals of curiosity and self-improvement; in effect leading it toward the edge of optimal complexity of interaction with its external environment. It posits interactive environments and artificial realities that display high levels of ambient artificial intelligence which are human-centric without being pre-determined or task-centric. The resulting prototype installations will permit a broader bandwidth of complex, meaningful, and open-ended interchange between the worlds of the human and of the surrounding mediascape.</p>
<p>Sound is an emotively significant yet relatively underexplored as a spatial, cyber-physical medium. Acoustic audio feedback is generally regarded as a problem to be suppressed, yet belongs to a larger class of nonlinear dynamical systems that includes most living systems. Operating through an acoustic medium permits response to the acoustic resonances of real physical spaces and built environments, and an unrestricted range of responses from participants at levels of temporal resolution unavailable in visual and tactile media.</p>
<h2 id="publications">Publications</h2>
<ul>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. Conservation of Shadows: Site-Specific Shared Physicality. Proceedings of ISEA 2019 (forthcoming).</li>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. <a href="https://www.leonardo.info/journal-issue/leonardo/51/4">&quot;Inhabitat: an Imaginary Ecosystem in a Children’s Science Museum.&quot;</a> Leonardo Vol. 51, No. 4, pp. 343–348, 2018. (Leonardo 50th anniversary issue, SIGGRAPH 2018 special issue)</li>
<li>Graham Wakefield. &quot;Open Worlds: Bergson And Computational Ontology.&quot; In <a href="http://worldmakingastechne.net/">Worldmaking as Techné</a>: Exploring Worlds of Participatory Art, Architecture, and Music, edited by Alberto de Campo, Mark-David Hosale, Sana Murrani. Riverside Architectural Press, 2018.</li>
<li>Charles Roberts, Graham Wakefield. &quot;Tensions &amp; Techniques in Live Coding Performance.&quot; In The Oxford Handbook of Algorithmic Music, edited by Roger Dean, Alex McLean. Oxford University Press, February 2018.</li>
<li>Charles Roberts, Graham Wakefield, Matthew Wright. &quot;Reflections on Synthesis and Instrument Design for the Browser” and “The Web Browser As Synthesizer And Interface.&quot; In The NIME Reader. Springer Verlag, Jan 2018.</li>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. [&quot;Biotopes Computationnels (Computational Biotopes)&quot;<a href="https://www.pca-stream.com/fr/articles/haru-ji-graham-wakefield-biotopes-computationnels-110">https://www.pca-stream.com/fr/articles/haru-ji-graham-wakefield-biotopes-computationnels-110</a>) In Stream 04: Les Paradoxes du vivant (The Paradoxes of the Living), pp. 304-316 Philippe Chiambaretta Architecte, Paris, November 2017.</li>
<li>Graham Wakefield, Charles Roberts. A Virtual Machine for Live Coding Language Design. Proceedings of the International Conference on New Interfaces for Musical Expression (Copenhagen, Denmark). 2017.</li>
<li>Charles Roberts, Graham Wakefield. gibberwocky: New Live-Coding Instruments for Musical Performance. Proceedings of the International Conference on New Interfaces for Musical Expression (Copenhagen, Denmark). 2017.</li>
<li>Sung-A Jang, Graham Wakefield, Sung-Hee Lee. &quot;Incorporating Kinesthetic Creativity and Gestural Play into Immersive Modeling.&quot; In Proceedings of the 4th International Conference on Motion Computing (London, United Kingdom), 17-24. ACM, June, 2017.</li>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. &quot;Recent Realizations of Artificial Nature.&quot; In Living Architecture Systems Group White Papers. Riverside Architectural Press, 2016.</li>
<li>Charles Roberts, Graham Wakefield. &quot;Live Coding the Digital Audio Workstation.&quot; In Proceedings of the International Conference on Live Coding (Hamilton, Canada). October, 2016.</li>
<li>Seunghun Kim, Graham Wakefield, Juhan Nam. &quot;Augmenting Environmental Interaction in Audio Feedback Systems.&quot; Applied Sciences 6, no. 5 (May, 2016): 125.</li>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. &quot;Endogenous Biologically Inspired Art of Complex Systems.&quot; Computer Graphics and Applications 36, no. 1 (January, 2016): 16-21. IEEE Computer Society.</li>
<li>Seunghun Kim, Changheun Oh, Graham Wakefield, Juhan Nam. &quot;Sonic Participation in the Evolving Audio Feedback System.&quot; In Proceedings of the International Symposium of Electronic Art (Hong Kong). 2016.</li>
<li>Charles Roberts, Graham Wakefield, Matthew Wright, JoAnn Kuchera-Morin. &quot;Designing Musical Instruments for the Browser.&quot; Computer Music Journal , no. 1 (March, 2015): 27-40. MIT Press.</li>
<li>Seunghun Kim, Juhan Nam, Graham Wakefield. &quot;Toward Certain Sonic Properties of an Audio Feedback System by Evolutionary Control of Second-Order Structures.&quot; In Lecture Notes in Computer Science 9027 Evolutionary and Biologically Inspired Music, Sound, Art and Design (The 4th International Conference EvoMUSART, Copenhagen), 113-124. Springer International Publishing, , 2015.</li>
<li>Haru (Hyunkyung) Ji, Graham Wakefield. &quot;Endogenous Biologically-Inspired Visualization Immersed Within an Art of Complex Systems.&quot; In Proceedings of the IEEE VIS Arts Program (Chicago, USA), 30-37. University of Illinois at Chicago, October, 2015.</li>
<li>Seunghun Kim, Graham Wakefield, Juhan Nam. &quot;Augmenting Room Acoustics and System Interaction for Intentional Control of Audio Feedback.&quot; In Proceedings of the International Computer Music Conference (Denton, USA). University of North Texas, September, 2015.</li>
<li>So Jung Bahng, Patrick Hutchings, Yoo Doo Won, Graham Wakefield. &quot;Generative Spatial Montage with Multi-Layered Screens in \&quot;Lost Fragments of Night\&quot;.&quot; In Proceedings of the International Symposium on Electronic Arts (Dubai). The Inter-Society for the Electronic Arts, October, 2014. </li>
</ul>
<h2 id="exhibitions">Exhibitions</h2>
<ul>
<li>Conservation of Shadows: Underworld. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield. &quot;Feral Hospitality&quot;, Sidewalk Labs, Toronto. 2018-03-02.</li>
<li>Infranet: Gwangju. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Gwangju Media Art Festival 2018 &quot;Algorithm Society: Birth of The Machine-God&quot;, Asia Culture Center (ACC), Gwangju, Korea. 2018-11-28 - 2018-12-7.</li>
<li>Insuperposition. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Daejeon Bienalle 2018 &quot;Bio&quot;, Daejeon Museum of Art, Daejeon, Korea. 2018-07-16 - 2017-10-24. </li>
<li>Conservation of Shadows. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield. Requiem for Hybrid Life, Seoul Museum of Art (Chang-go), Seoul, Korea. 2017-10-17 - 2017-10-23 (Curated, International).</li>
<li>Inhabitat. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Interactive Media Theatre. MOXI Museum of Exploration of Innovation, Santa Barbara, USA.  2017-08-10 - 2018-01-08 (Commissioned, International).</li>
<li>Portrait. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  First Thursday Festival. SBCAST, Santa Barbara, USA.  2017-08-03 (Curated, Local).</li>
<li>Portrait. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Currents New Media Festival. El Museo Cultural, Santa Fe, USA.  2017-06-09 - 2017-06-25 (Juried, International).</li>
<li>Endless Current. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  SV+VS (Sonifying Visuals+Visualizing Sound). Gallery MUN, Dongdaemun Design Plaza, Seoul, Korea.  2016-08-20 - 2016-09-18 (Curated, International).</li>
<li>Endless Current. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Currents New Media Festival. El Museo Cultural, and also the Digital Dome at the Institute of American Indian Arts, Santa Fe, USA.  2016-06-10 - 2016-06-26 (Juried, International).</li>
<li>Live Electronic Music. Graham Wakefield.  Wordless Word. Array Space, Toronto, Canada.  2016-05-10 (Curated, National).</li>
<li>Time of Doubles. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Globale Renaissance 2.0 - Exo:Evolution. Center for Art and Media (ZKM) Mediamuseum, Karlsruhe, Germany.  2015-10-30 - 2016-02-28 (Curated, International).</li>
<li>Endless Current. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  IEEE VIS Arts Program. LeRoy Neiman Center, School of the Art Institute of Chicago, USA.  2015-10-16 - 2015-10-30 (Juried, International).</li>
<li>Archipelago. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Seoul Sangsangryok Baljeonso (Imagination Powerhouse). City Hall, Seoul, Korea.  2015-02-16 - 2015-02-27 (Invited re-exhibit, International).</li>
<li>Archipelago. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Capitaine Futur. La Gat Lyrique, Paris, France.  2014-10-08 - 2015-02-08 (Curated, International).</li>
<li>Archipelago. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Seoul Sangsangryok Baljeonso (Imagination Powerhouse). City Hall, Seoul, Korea.  2014-10-01 - 2014-10-21 (Juried competition, International).</li>
<li>Endless Current. Artificial Nature: Haru (Hyunkyung) Ji and Graham Wakefield.  Artience Project Daejeon. Korea Research Institute of Standards and Science, Daejeon, Korea.  2014-08-23 - 2014-09-02 (Curated, National).</li>
</ul>
<h2 id="talks-panels-guest-lectures-and-workshops">Talks, panels, guest lectures, and workshops</h2>
<p><em>(Excluding conference presentations with publications)</em></p>
<ul>
<li>Live Code a Language as Instrument (Workshop). 
The International Conference on New Interfaces for Musical Expression, Aalborg University Copenhagen, Denmark, 2017-06-15</li>
<li>Design a Mini Live Coding Language (Workshop). International Conference on Live Coding, Centre 3 for Print and Media Arts, Hamilton, Canada, 2016-10-12</li>
<li>Artificial Natures (Artist talk). Weird Reality: Head-Mounted Art &amp;&amp; Code, Carnegie Mellon University, Pittsburgh, USA, 2016-10-08</li>
<li>Interactive Art: Animating Public Space (Panel talk). Media Architecture Summit 2016, oTIFF Bell Lightbox, Toronto, Canada, 2016-09-30</li>
<li>Computational Art in Mixed Realities (Research talk). Centre for Vision Research Retreat, York Glendon Hall, Toronto, Canada, 2016-09-16</li>
<li>Computational Worldmaking (Guest lecture). Graduate Seminar, School of Interactive Games &amp; Media, Rochester Institute of Technology, USA, 2016-09-01</li>
<li>Virtual Reality Worldmaking (Lecture/workshop). Imagination Seminar, Art &amp; Technology program, Sogang University, Korea, 2016-07-15</li>
<li>Artificial Natures (Guest lecture). Future City Society, SCALe, Korea, 2016-07-13</li>
<li>Advanced Gen Programming (Workshop). TACIT media studio, Korea, 2016-07-08</li>
<li>Artificial Natures (Guest lecture). Computational Aesthetics, School of Interactive Games &amp; Media, Rochester Institute of Technology, USA, 2016-03-07</li>
<li>Data Imaginaries (Artist talk). Leonardo Art Science Evening Rendezvouz (LASER) / Art-Science Salon, Fields Institute, University of Toronto, Canada, 2015-11-19</li>
<li>Computational Worldmaking (Artist talk). Centre for Vision Research seminar series, York University, Toronto, Canada, 2015-11-06</li>
<li>Bridging Web-Based Visualization and 3D (Workshop). Canadian Visual Analytics School (CANVAS), York University, Toronto, Canada, 2015-07-28</li>
<li>Artificial Nature: Mixed-Reality Ecosystem (Construction of Aesthetic Experience) (Forum talk). Asia Pacific Center for Theoretical Physics (APCTP) Science Communication Forum, Korea Astronomy and Space Science Institute, Sobaek Optical Astronomy Observatory, Republic of Korea, 2015.07.08 - 2015.07.10</li>
<li>Introduction to Artificial Life (Workshop). Seoul Science High School, Korea, 2015-07-06</li>
<li>Becoming There: Immersed in Computation (Artist talk). Sensorium Lecture Series, York University, Toronto, Canada, 2015-02-24</li>
<li>Becoming There: Immersed in Computation (Panel). Exploring the Frontiers of Science &amp; Technology, York University, Toronto, Canada, 2015-01-28</li>
</ul>
<h2 id="students">Students</h2>
<ul>
<li>Sarah Vollmer, MSc Digital Media.</li>
<li>David Han, PhD Cinema and Media Studies.</li>
<li>Michael Palumbo, PhD Theatre &amp; Performance Studies.</li>
<li>Michael Trommer, PhD Cinema and Media Studies.</li>
<li>Alison Humphrey, PhD Cinema and Media Studies.</li>
<li>Reşat Fuat Çam. PhD Cinema and Media Studies.</li>
<li>Alia Miroshnichenko, PhD Communications and Culture.</li>
<li><p>Slavica Ceperkovic, PhD Cinema and Media Studies.</p>
</li>
<li><p>Nicole Skrypuch, Digital Media program.</p>
</li>
<li>Filiz Eryilmaz, Digital Media program.</li>
<li>Amir Bahador Rostami, Digital Media program.</li>
<li>Adiola Palmer, Digital Media program.</li>
<li>Alex Zonta, Digital Media program.</li>
<li>Andrew Sidsworth, Digital Media program.</li>
<li>Nicholas Abbruzzese, Digital Media program.</li>
<li>Zachary Shron, Digital Media program.</li>
<li>Nick Erkelenz, Digital Media program.</li>
<li>Sam Bebenek, Digital Media program.</li>
<li>Rory Hoy, Digital Media program.</li>
<li>Dale Rosen, Digital Media program.</li>
<li>Lalaine Ulit-Destajo, Digital Media program, graduated 2016.</li>
<li>Youhan Guan, Digital Media program, graduated 2016.</li>
<li><p>Mengmei Zhou, Digital Media program, graduated 2016.</p>
</li>
<li><p>Seunghun Kim, PhD Culture Technology (KAIST), graduated 2015.</p>
</li>
<li>Sunga Jang, MS Culture Technology (KAIST), graduated 2015.</li>
<li>Sojung Bahng, MS Culture Technology (KAIST), graduated 2015.</li>
</ul>
<h3 id="location">Location</h3>
<p><a href="https://www.google.com/maps/place/York+University+-+School+of+the+Arts,+Media,+Performance+%26+Design/@43.7720603,-79.5042865,17z/data=!3m1!4b1!4m5!3m4!1s0x882b2e2503c24255:0x2cc3089a2eef129!8m2!3d43.7720603!4d-79.5020978">Room 309, Goldfarb Center for Fine Arts,<br>School of the Arts, Media, Performance, and Design, York University,<br>86 Fine Arts Rd, Toronto, ON M3J 1P3, Canada</a></p>
<p>Getting there from the York University TTC Subway station:</p>
<iframe src="https://www.google.com/maps/d/embed?mid=1D6CuFDSm6UU3noagSocNRw7kbyFnvsVu" width="640" height="480"></iframe>

<p><a class="button button-primary" href="https://calendar.google.com/calendar/embed?src=i6gs0tohrmg0rv6umrfqklo9co%40group.calendar.google.com&ctz=America/Toronto">Lab booking calendar</a></p>
<h3 id="related-labs-and-organized-research-units-at-york-and-beyond">Related labs and organized research units at York and beyond</h3>
<ul>
<li><a href="http://dispersionlab.weebly.com">The DisPerSion Lab</a></li>
<li><a href="http://www.ndstudiolab.com">The n-D::StudioLab</a></li>
<li><a href="http://ar.lab.yorku.ca">The Augmented Reality Lab</a></li>
<li><a href="http://futurecinema.lab.yorku.ca">The Future Cinema Lab</a></li>
<li><a href="http://www.cvr.yorku.ca">The Centre for Vision Research</a></li>
<li><a href="http://sensorium.info.yorku.ca">Sensorium</a></li>
<li><a href="http://www.allosphere.ucsb.edu">The AlloSphere Research Facility at UC Santa Barbara</a></li>
<li><a href="https://www.evl.uic.edu/creativecoding/">The EVL Creative Coding Research Group at The University of Illinois Chicago</a></li>
<li><a href="http://mac.kaist.ac.kr/index.html">The Music and Audio Computing lab at KAIST</a></li>
</ul>
<hr>
<p>Why Alice? Because of the wonderland of the child traversing the paradoxical <a href="https://books.google.co.kr/books?id=PKfBPrRda4sC&amp;redir_esc=y">the logic of sense</a> of the mathematician, through which Sutherland&#39;s <a href="http://worrydream.com/refs/Sutherland%20-%20The%20Ultimate%20Display.pdf">Ultimate Display</a> (1965) might allow us to wander, and because it echoes <a href="http://www.thefreedictionary.com/allo-"><em>allos</em></a>, origin of alias, else, alter, and alien. Not an acronym, but if it were perhaps it could be artificial life &amp; interactive computational embodiment, or algorithmic, immersive, and collaborative enlivement, augmented live coded environments, or otherwise... </p>

</section>
<!--
<aside>

</aside>
-->
</main>

<div id="bottom">
<footer>
&copy; 2016 Graham Wakefield, grrrwaaa at yorku dot ca
</footer>
</div>

</body>